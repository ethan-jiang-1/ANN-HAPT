https://github.com/nishantml/Human-activity-detection/blob/master/HAR_LSTM.ipynb

simple LTSM ANN with multiple layers and dropout


# Initiliazing the sequential model
model = Sequential()
# Configuring the parameters
model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim)))
# Adding a dropout layer
model.add(Dropout(0.5))
# Adding a dense output layer with sigmoid activation
model.add(Dense(n_classes, activation='sigmoid'))
model.summary()

# Compiling the model
model.compile(loss='categorical_crossentropy',
              optimizer='rmsprop',
              metrics=['accuracy'])
# Training the model
model.fit(X_train,
          Y_train,
          batch_size=batch_size,
          validation_data=(X_test, Y_test),
          epochs=epochs)

Train on 7352 samples, validate on 2947 samples
Epoch 1/30
7352/7352 [==============================] - 98s 13ms/step - loss: 1.3139 - acc: 0.4358 - val_loss: 1.1352 - val_acc: 0.4700
Epoch 2/30
7352/7352 [==============================] - 107s 15ms/step - loss: 0.9788 - acc: 0.5773 - val_loss: 0.9513 - val_acc: 0.5884
Epoch 3/30
7352/7352 [==============================] - 106s 14ms/step - loss: 0.7977 - acc: 0.6457 - val_loss: 0.8343 - val_acc: 0.6013
Epoch 4/30
7352/7352 [==============================] - 96s 13ms/step - loss: 0.6989 - acc: 0.6582 - val_loss: 0.7532 - val_acc: 0.6098
Epoch 5/30
7352/7352 [==============================] - 89s 12ms/step - loss: 0.6359 - acc: 0.6797 - val_loss: 0.7335 - val_acc: 0.6183
Epoch 6/30
7352/7352 [==============================] - 111s 15ms/step - loss: 0.5819 - acc: 0.6865 - val_loss: 0.8786 - val_acc: 0.6098
Epoch 7/30
7352/7352 [==============================] - 103s 14ms/step - loss: 0.5676 - acc: 0.7058 - val_loss: 0.8191 - val_acc: 0.6132
Epoch 8/30
7352/7352 [==============================] - 108s 15ms/step - loss: 0.5583 - acc: 0.7217 - val_loss: 0.6639 - val_acc: 0.7190
Epoch 9/30
7352/7352 [==============================] - 105s 14ms/step - loss: 0.5386 - acc: 0.7557 - val_loss: 0.6388 - val_acc: 0.7167
Epoch 10/30
7352/7352 [==============================] - 98s 13ms/step - loss: 0.4804 - acc: 0.7911 - val_loss: 0.5077 - val_acc: 0.7509
Epoch 11/30
7352/7352 [==============================] - 97s 13ms/step - loss: 0.4320 - acc: 0.8052 - val_loss: 0.5143 - val_acc: 0.7418
Epoch 12/30
7352/7352 [==============================] - 105s 14ms/step - loss: 0.4279 - acc: 0.8062 - val_loss: 0.4951 - val_acc: 0.7472
Epoch 13/30
7352/7352 [==============================] - 109s 15ms/step - loss: 0.3911 - acc: 0.8130 - val_loss: 0.5606 - val_acc: 0.7516
Epoch 14/30
7352/7352 [==============================] - 99s 13ms/step - loss: 0.3898 - acc: 0.8313 - val_loss: 0.4518 - val_acc: 0.8137
Epoch 15/30
7352/7352 [==============================] - 78s 11ms/step - loss: 0.3308 - acc: 0.8942 - val_loss: 0.4732 - val_acc: 0.8633
Epoch 16/30
7352/7352 [==============================] - 43s 6ms/step - loss: 0.2891 - acc: 0.9176 - val_loss: 0.3794 - val_acc: 0.8765
Epoch 17/30
7352/7352 [==============================] - 49s 7ms/step - loss: 0.2660 - acc: 0.9246 - val_loss: 0.5082 - val_acc: 0.8660
Epoch 18/30
7352/7352 [==============================] - 52s 7ms/step - loss: 0.2538 - acc: 0.9251 - val_loss: 0.4772 - val_acc: 0.8806
Epoch 19/30
7352/7352 [==============================] - 45s 6ms/step - loss: 0.2502 - acc: 0.9312 - val_loss: 0.7013 - val_acc: 0.8307
Epoch 20/30
7352/7352 [==============================] - 46s 6ms/step - loss: 0.1980 - acc: 0.9382 - val_loss: 0.3988 - val_acc: 0.8890
Epoch 21/30
7352/7352 [==============================] - 46s 6ms/step - loss: 0.2018 - acc: 0.9372 - val_loss: 1.7682 - val_acc: 0.7075
Epoch 22/30
7352/7352 [==============================] - 46s 6ms/step - loss: 0.2455 - acc: 0.9310 - val_loss: 0.5812 - val_acc: 0.8687
Epoch 23/30
7352/7352 [==============================] - 50s 7ms/step - loss: 0.2194 - acc: 0.9329 - val_loss: 0.6468 - val_acc: 0.8744
Epoch 24/30
7352/7352 [==============================] - 50s 7ms/step - loss: 0.2282 - acc: 0.9304 - val_loss: 0.4721 - val_acc: 0.8741
Epoch 25/30
7352/7352 [==============================] - 46s 6ms/step - loss: 0.2166 - acc: 0.9359 - val_loss: 0.4131 - val_acc: 0.8938
Epoch 26/30
7352/7352 [==============================] - 46s 6ms/step - loss: 0.2173 - acc: 0.9350 - val_loss: 0.4841 - val_acc: 0.8887
Epoch 27/30
7352/7352 [==============================] - 48s 7ms/step - loss: 0.2224 - acc: 0.9353 - val_loss: 0.3590 - val_acc: 0.8935
Epoch 28/30
7352/7352 [==============================] - 46s 6ms/step - loss: 0.1961 - acc: 0.9385 - val_loss: 0.5297 - val_acc: 0.8802
Epoch 29/30
7352/7352 [==============================] - 45s 6ms/step - loss: 0.1876 - acc: 0.9416 - val_loss: 0.4324 - val_acc: 0.8924
Epoch 30/30
7352/7352 [==============================] - 45s 6ms/step - loss: 0.1999 - acc: 0.9411 - val_loss: 0.4883 - val_acc: 0.8829
Out[18]:
